//
// DO NOT EDIT.
//
// Generated by the protocol buffer compiler.
// Source: google/cloud/speech/v1/cloud_speech.proto
//

//
// Copyright 2018, gRPC Authors All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
import GRPC
import NIO
import NIOConcurrencyHelpers
import SwiftProtobuf


/// Service that implements Google Cloud Speech API.
///
/// Usage: instantiate `Google_Cloud_Speech_V1_SpeechClient`, then call methods of this protocol to make API calls.
public protocol Google_Cloud_Speech_V1_SpeechClientProtocol: GRPCClient {
  var serviceName: String { get }
  var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? { get }

  func recognize(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions?
  ) -> UnaryCall<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse>

  func longRunningRecognize(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions?
  ) -> UnaryCall<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation>

  func streamingRecognize(
    callOptions: CallOptions?,
    handler: @escaping (Google_Cloud_Speech_V1_StreamingRecognizeResponse) -> Void
  ) -> BidirectionalStreamingCall<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse>
}

extension Google_Cloud_Speech_V1_SpeechClientProtocol {
  public var serviceName: String {
    return "google.cloud.speech.v1.Speech"
  }

  /// Performs synchronous speech recognition: receive results after all audio
  /// has been sent and processed.
  ///
  /// - Parameters:
  ///   - request: Request to send to Recognize.
  ///   - callOptions: Call options.
  /// - Returns: A `UnaryCall` with futures for the metadata, status and response.
  public func recognize(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions? = nil
  ) -> UnaryCall<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse> {
    return self.makeUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.recognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeRecognizeInterceptors() ?? []
    )
  }

  /// Performs asynchronous speech recognition: receive results via the
  /// google.longrunning.Operations interface. Returns either an
  /// `Operation.error` or an `Operation.response` which contains
  /// a `LongRunningRecognizeResponse` message.
  /// For more information on asynchronous speech recognition, see the
  /// [how-to](https://cloud.google.com/speech-to-text/docs/async-recognize).
  ///
  /// - Parameters:
  ///   - request: Request to send to LongRunningRecognize.
  ///   - callOptions: Call options.
  /// - Returns: A `UnaryCall` with futures for the metadata, status and response.
  public func longRunningRecognize(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions? = nil
  ) -> UnaryCall<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation> {
    return self.makeUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.longRunningRecognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeLongRunningRecognizeInterceptors() ?? []
    )
  }

  /// Performs bidirectional streaming speech recognition: receive results while
  /// sending audio. This method is only available via the gRPC API (not REST).
  ///
  /// Callers should use the `send` method on the returned object to send messages
  /// to the server. The caller should send an `.end` after the final message has been sent.
  ///
  /// - Parameters:
  ///   - callOptions: Call options.
  ///   - handler: A closure called when each response is received from the server.
  /// - Returns: A `ClientStreamingCall` with futures for the metadata and status.
  public func streamingRecognize(
    callOptions: CallOptions? = nil,
    handler: @escaping (Google_Cloud_Speech_V1_StreamingRecognizeResponse) -> Void
  ) -> BidirectionalStreamingCall<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse> {
    return self.makeBidirectionalStreamingCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? [],
      handler: handler
    )
  }
}

#if compiler(>=5.6)
@available(*, deprecated)
extension Google_Cloud_Speech_V1_SpeechClient: @unchecked Sendable {}
#endif // compiler(>=5.6)

@available(*, deprecated, renamed: "Google_Cloud_Speech_V1_SpeechNIOClient")
public final class Google_Cloud_Speech_V1_SpeechClient: Google_Cloud_Speech_V1_SpeechClientProtocol {
  private let lock = Lock()
  private var _defaultCallOptions: CallOptions
  private var _interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol?
  public let channel: GRPCChannel
  public var defaultCallOptions: CallOptions {
    get { self.lock.withLock { return self._defaultCallOptions } }
    set { self.lock.withLockVoid { self._defaultCallOptions = newValue } }
  }
  public var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? {
    get { self.lock.withLock { return self._interceptors } }
    set { self.lock.withLockVoid { self._interceptors = newValue } }
  }

  /// Creates a client for the google.cloud.speech.v1.Speech service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self._defaultCallOptions = defaultCallOptions
    self._interceptors = interceptors
  }
}

public struct Google_Cloud_Speech_V1_SpeechNIOClient: Google_Cloud_Speech_V1_SpeechClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol?

  /// Creates a client for the google.cloud.speech.v1.Speech service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#if compiler(>=5.6)
/// Service that implements Google Cloud Speech API.
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public protocol Google_Cloud_Speech_V1_SpeechAsyncClientProtocol: GRPCClient {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? { get }

  func makeRecognizeCall(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions?
  ) -> GRPCAsyncUnaryCall<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse>

  func makeLongRunningRecognizeCall(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions?
  ) -> GRPCAsyncUnaryCall<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation>

  func makeStreamingRecognizeCall(
    callOptions: CallOptions?
  ) -> GRPCAsyncBidirectionalStreamingCall<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse>
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Google_Cloud_Speech_V1_SpeechAsyncClientProtocol {
  public static var serviceDescriptor: GRPCServiceDescriptor {
    return Google_Cloud_Speech_V1_SpeechClientMetadata.serviceDescriptor
  }

  public var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? {
    return nil
  }

  public func makeRecognizeCall(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncUnaryCall<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse> {
    return self.makeAsyncUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.recognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeRecognizeInterceptors() ?? []
    )
  }

  public func makeLongRunningRecognizeCall(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncUnaryCall<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation> {
    return self.makeAsyncUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.longRunningRecognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeLongRunningRecognizeInterceptors() ?? []
    )
  }

  public func makeStreamingRecognizeCall(
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncBidirectionalStreamingCall<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse> {
    return self.makeAsyncBidirectionalStreamingCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Google_Cloud_Speech_V1_SpeechAsyncClientProtocol {
  public func recognize(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions? = nil
  ) async throws -> Google_Cloud_Speech_V1_RecognizeResponse {
    return try await self.performAsyncUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.recognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeRecognizeInterceptors() ?? []
    )
  }

  public func longRunningRecognize(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions? = nil
  ) async throws -> Google_Longrunning_Operation {
    return try await self.performAsyncUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.longRunningRecognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeLongRunningRecognizeInterceptors() ?? []
    )
  }

  public func streamingRecognize<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Google_Cloud_Speech_V1_StreamingRecognizeResponse> where RequestStream: Sequence, RequestStream.Element == Google_Cloud_Speech_V1_StreamingRecognizeRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? []
    )
  }

  public func streamingRecognize<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Google_Cloud_Speech_V1_StreamingRecognizeResponse> where RequestStream: AsyncSequence & Sendable, RequestStream.Element == Google_Cloud_Speech_V1_StreamingRecognizeRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public struct Google_Cloud_Speech_V1_SpeechAsyncClient: Google_Cloud_Speech_V1_SpeechAsyncClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol?

  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#endif // compiler(>=5.6)

public protocol Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol: GRPCSendable {

  /// - Returns: Interceptors to use when invoking 'recognize'.
  func makeRecognizeInterceptors() -> [ClientInterceptor<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse>]

  /// - Returns: Interceptors to use when invoking 'longRunningRecognize'.
  func makeLongRunningRecognizeInterceptors() -> [ClientInterceptor<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation>]

  /// - Returns: Interceptors to use when invoking 'streamingRecognize'.
  func makeStreamingRecognizeInterceptors() -> [ClientInterceptor<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse>]
}

public enum Google_Cloud_Speech_V1_SpeechClientMetadata {
  public static let serviceDescriptor = GRPCServiceDescriptor(
    name: "Speech",
    fullName: "google.cloud.speech.v1.Speech",
    methods: [
      Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.recognize,
      Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.longRunningRecognize,
      Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize,
    ]
  )

  public enum Methods {
    public static let recognize = GRPCMethodDescriptor(
      name: "Recognize",
      path: "/google.cloud.speech.v1.Speech/Recognize",
      type: GRPCCallType.unary
    )

    public static let longRunningRecognize = GRPCMethodDescriptor(
      name: "LongRunningRecognize",
      path: "/google.cloud.speech.v1.Speech/LongRunningRecognize",
      type: GRPCCallType.unary
    )

    public static let streamingRecognize = GRPCMethodDescriptor(
      name: "StreamingRecognize",
      path: "/google.cloud.speech.v1.Speech/StreamingRecognize",
      type: GRPCCallType.bidirectionalStreaming
    )
  }
}

